"""
PyTorch å¿«é€Ÿå…¥é—¨æ•™ç¨‹

æœ¬æ•™ç¨‹æ˜¯PyTorchçš„å®Œæ•´å…¥é—¨æŒ‡å—ï¼Œæ¶µç›–äº†æœºå™¨å­¦ä¹ é¡¹ç›®çš„ä¸»è¦æ­¥éª¤ï¼š
1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
2. æ¨¡å‹å®šä¹‰å’Œæ¶æ„è®¾è®¡
3. è®­ç»ƒå¾ªç¯å’Œä¼˜åŒ–
4. æ¨¡å‹è¯„ä¼°å’Œæµ‹è¯•
5. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
6. å®é™…é¢„æµ‹åº”ç”¨

å­¦ä¹ ç›®æ ‡ï¼š
- æŒæ¡PyTorchçš„åŸºæœ¬å·¥ä½œæµç¨‹
- ç†è§£æ·±åº¦å­¦ä¹ é¡¹ç›®çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
- å­¦ä¼šæ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°çš„æ ‡å‡†åšæ³•
- èƒ½å¤Ÿç‹¬ç«‹å®Œæˆä¸€ä¸ªå®Œæ•´çš„åˆ†ç±»é¡¹ç›®

`Learn the Basics <intro.html>`_ ||
**Quickstart** ||
`Tensors <tensorqs_tutorial.html>`_ ||
`Datasets & DataLoaders <data_tutorial.html>`_ ||
`Transforms <transforms_tutorial.html>`_ ||
`Build Model <buildmodel_tutorial.html>`_ ||
`Autograd <autogradqs_tutorial.html>`_ ||
`Optimization <optimization_tutorial.html>`_ ||
`Save & Load Model <saveloadrun_tutorial.html>`_

å¿«é€Ÿå…¥é—¨
===================
æœ¬èŠ‚ä»‹ç»æœºå™¨å­¦ä¹ å¸¸è§ä»»åŠ¡çš„APIã€‚è¯·å‚è€ƒæ¯èŠ‚ä¸­çš„é“¾æ¥ä»¥æ·±å…¥äº†è§£ã€‚

å¤„ç†æ•°æ®
-----------------
PyTorchæœ‰ä¸¤ä¸ª `å¤„ç†æ•°æ®çš„åŸºæœ¬ç»„ä»¶ <https://pytorch.org/docs/stable/data.html>`_ï¼š
``torch.utils.data.DataLoader`` å’Œ ``torch.utils.data.Dataset``ã€‚
``Dataset`` å­˜å‚¨æ ·æœ¬åŠå…¶å¯¹åº”çš„æ ‡ç­¾ï¼Œ``DataLoader`` åœ¨ ``Dataset`` å‘¨å›´åŒ…è£…ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ã€‚

"""

import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

######################################################################
# æ•°æ®é›†è·å–å’ŒåŠ è½½
# PyTorchæä¾›ç‰¹å®šé¢†åŸŸçš„åº“ï¼Œå¦‚ `TorchText <https://pytorch.org/text/stable/index.html>`_ã€
# `TorchVision <https://pytorch.org/vision/stable/index.html>`_ å’Œ `TorchAudio <https://pytorch.org/audio/stable/index.html>`_ï¼Œ
# æ‰€æœ‰è¿™äº›éƒ½åŒ…å«æ•°æ®é›†ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨TorchVisionæ•°æ®é›†ã€‚
#
# ``torchvision.datasets`` æ¨¡å—åŒ…å«è®¸å¤šçœŸå®ä¸–ç•Œè§†è§‰æ•°æ®çš„ ``Dataset`` å¯¹è±¡ï¼Œå¦‚
# CIFARã€COCOï¼ˆ`å®Œæ•´åˆ—è¡¨åœ¨è¿™é‡Œ <https://pytorch.org/vision/stable/datasets.html>`_ï¼‰ã€‚
# åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨FashionMNISTæ•°æ®é›†ã€‚æ¯ä¸ªTorchVision ``Dataset`` éƒ½åŒ…å«ä¸¤ä¸ªå‚æ•°ï¼š
# ``transform`` å’Œ ``target_transform`` åˆ†åˆ«ç”¨äºä¿®æ”¹æ ·æœ¬å’Œæ ‡ç­¾ã€‚

print("="*60)
print("æ­¥éª¤1ï¼šåŠ è½½å’Œå‡†å¤‡æ•°æ®")
print("="*60)

# ä»å¼€æ”¾æ•°æ®é›†ä¸‹è½½è®­ç»ƒæ•°æ®
# FashionMNISTï¼šæ—¶å°šç‰©å“çš„å›¾åƒåˆ†ç±»æ•°æ®é›†ï¼ŒåŒ…å«10ä¸ªç±»åˆ«
print("æ­£åœ¨ä¸‹è½½è®­ç»ƒæ•°æ®...")
training_data = datasets.FashionMNIST(
    root="data",           # æ•°æ®å­˜å‚¨è·¯å¾„
    train=True,            # ä¸‹è½½è®­ç»ƒé›†
    download=True,         # å¦‚æœæ•°æ®ä¸å­˜åœ¨åˆ™ä¸‹è½½
    transform=ToTensor(),  # å°†PILå›¾åƒæˆ–numpyæ•°ç»„è½¬æ¢ä¸ºå¼ é‡
)

# ä»å¼€æ”¾æ•°æ®é›†ä¸‹è½½æµ‹è¯•æ•°æ®
print("æ­£åœ¨ä¸‹è½½æµ‹è¯•æ•°æ®...")
test_data = datasets.FashionMNIST(
    root="data",           # æ•°æ®å­˜å‚¨è·¯å¾„
    train=False,           # ä¸‹è½½æµ‹è¯•é›†
    download=True,         # å¦‚æœæ•°æ®ä¸å­˜åœ¨åˆ™ä¸‹è½½
    transform=ToTensor(),  # æ•°æ®ç±»å‹è½¬æ¢
)

print(f"è®­ç»ƒæ ·æœ¬æ•°é‡: {len(training_data)}")
print(f"æµ‹è¯•æ ·æœ¬æ•°é‡: {len(test_data)}")
print(f"å›¾åƒå°ºå¯¸: {training_data[0][0].shape}")  # (C, H, W)
print(f"ç±»åˆ«æ•°é‡: {len(training_data.classes)}")
print(f"ç±»åˆ«åç§°: {training_data.classes}")

######################################################################
# åˆ›å»ºæ•°æ®åŠ è½½å™¨
# æˆ‘ä»¬å°† ``Dataset`` ä½œä¸ºå‚æ•°ä¼ é€’ç»™ ``DataLoader``ã€‚è¿™åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸ŠåŒ…è£…äº†ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œ
# å¹¶æ”¯æŒè‡ªåŠ¨æ‰¹å¤„ç†ã€é‡‡æ ·ã€æ´—ç‰Œå’Œå¤šè¿›ç¨‹æ•°æ®åŠ è½½ã€‚è¿™é‡Œæˆ‘ä»¬å®šä¹‰æ‰¹æ¬¡å¤§å°ä¸º64ï¼Œ
# å³æ•°æ®åŠ è½½å™¨å¯è¿­ä»£å¯¹è±¡ä¸­çš„æ¯ä¸ªå…ƒç´ å°†è¿”å›ä¸€æ‰¹64ä¸ªç‰¹å¾å’Œæ ‡ç­¾ã€‚
#
# DataLoaderçš„é‡è¦ä½œç”¨ï¼š
# 1. æ‰¹å¤„ç†ï¼šå°†å•ä¸ªæ ·æœ¬ç»„åˆæˆæ‰¹æ¬¡ï¼Œæé«˜è®­ç»ƒæ•ˆç‡
# 2. æ´—ç‰Œï¼šéšæœºåŒ–æ ·æœ¬é¡ºåºï¼Œé¿å…æ¨¡å‹å­¦åˆ°æ•°æ®é¡ºåºçš„åè§
# 3. å¹¶è¡ŒåŠ è½½ï¼šä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿæ•°æ®åŠ è½½
# 4. å†…å­˜ç®¡ç†ï¼šæŒ‰éœ€åŠ è½½æ•°æ®ï¼Œé¿å…å†…å­˜æº¢å‡º

batch_size = 64  # æ¯æ‰¹å¤„ç†64ä¸ªæ ·æœ¬

print(f"\nä½¿ç”¨æ‰¹æ¬¡å¤§å°: {batch_size}")
print("æ‰¹æ¬¡å¤§å°çš„å½±å“ï¼š")
print("- è¾ƒå¤§æ‰¹æ¬¡ï¼šè®­ç»ƒç¨³å®šï¼Œä½†éœ€è¦æ›´å¤šå†…å­˜")
print("- è¾ƒå°æ‰¹æ¬¡ï¼šå†…å­˜å‹å¥½ï¼Œä½†å¯èƒ½è®­ç»ƒä¸ç¨³å®š")

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_dataloader = DataLoader(
    training_data, 
    batch_size=batch_size,
    shuffle=True,      # è®­ç»ƒæ—¶æ´—ç‰Œæ•°æ®
    num_workers=2      # ä½¿ç”¨2ä¸ªè¿›ç¨‹å¹¶è¡ŒåŠ è½½æ•°æ®
)
test_dataloader = DataLoader(
    test_data, 
    batch_size=batch_size,
    shuffle=False,     # æµ‹è¯•æ—¶ä¸éœ€è¦æ´—ç‰Œ
    num_workers=2
)

# æŸ¥çœ‹æ•°æ®çš„å½¢çŠ¶å’Œç±»å‹
print("\næ•°æ®æ‰¹æ¬¡ä¿¡æ¯ï¼š")
for X, y in test_dataloader:
    print(f"ç‰¹å¾å¼ é‡ X çš„å½¢çŠ¶ [N, C, H, W]: {X.shape}")
    print(f"- N (æ‰¹æ¬¡å¤§å°): {X.shape[0]}")
    print(f"- C (é€šé“æ•°): {X.shape[1]} (ç°åº¦å›¾åƒ)")
    print(f"- H (é«˜åº¦): {X.shape[2]} åƒç´ ")
    print(f"- W (å®½åº¦): {X.shape[3]} åƒç´ ")
    print(f"æ ‡ç­¾å¼ é‡ y çš„å½¢çŠ¶: {y.shape}, æ•°æ®ç±»å‹: {y.dtype}")
    print(f"æ ‡ç­¾èŒƒå›´: {y.min()} - {y.max()} (å¯¹åº”10ä¸ªç±»åˆ«)")
    break

######################################################################
# äº†è§£æ›´å¤šå…³äº `åœ¨PyTorchä¸­åŠ è½½æ•°æ® <data_tutorial.html>`_ çš„å†…å®¹ã€‚
#

######################################################################
# --------------
#

################################
# åˆ›å»ºæ¨¡å‹
# ------------------
print("\n" + "="*60)
print("æ­¥éª¤2ï¼šå®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹")
print("="*60)

# åœ¨PyTorchä¸­å®šä¹‰ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç»§æ‰¿è‡ª
# `nn.Module <https://pytorch.org/docs/stable/generated/torch.nn.Module.html>`_ çš„ç±»ã€‚
# æˆ‘ä»¬åœ¨ ``__init__`` å‡½æ•°ä¸­å®šä¹‰ç½‘ç»œçš„å±‚ï¼Œå¹¶åœ¨ ``forward`` å‡½æ•°ä¸­æŒ‡å®šæ•°æ®å¦‚ä½•é€šè¿‡ç½‘ç»œä¼ é€’ã€‚
# ä¸ºäº†åŠ é€Ÿç¥ç»ç½‘ç»œä¸­çš„æ“ä½œï¼Œæˆ‘ä»¬å°†å…¶ç§»åŠ¨åˆ° `åŠ é€Ÿå™¨ <https://pytorch.org/docs/stable/torch.html#accelerators>`__
# å¦‚CUDAã€MPSã€MTIAæˆ–XPUã€‚å¦‚æœå½“å‰åŠ é€Ÿå™¨å¯ç”¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒã€‚å¦åˆ™ï¼Œæˆ‘ä»¬ä½¿ç”¨CPUã€‚

# é€‰æ‹©è®¡ç®—è®¾å¤‡
device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else "cpu"
print(f"é€‰æ‹©çš„è®¡ç®—è®¾å¤‡: {device}")

if device == "cpu":
    print("æç¤ºï¼šæ­£åœ¨ä½¿ç”¨CPUè®­ç»ƒï¼Œé€Ÿåº¦å¯èƒ½è¾ƒæ…¢")
    print("å¦‚æœæœ‰GPUï¼Œè¯·ç¡®ä¿å®‰è£…äº†CUDAç‰ˆæœ¬çš„PyTorch")
else:
    print(f"å¤ªå¥½äº†ï¼æ­£åœ¨ä½¿ç”¨ {device} åŠ é€Ÿè®­ç»ƒ")

# å®šä¹‰æ¨¡å‹ç±»
class NeuralNetwork(nn.Module):
    """
    ç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œç”¨äºå›¾åƒåˆ†ç±»
    
    ç½‘ç»œæ¶æ„ï¼š
    è¾“å…¥(28x28å›¾åƒ) -> å±•å¹³ -> å…¨è¿æ¥å±‚(784->512) -> ReLU -> 
    å…¨è¿æ¥å±‚(512->512) -> ReLU -> è¾“å‡ºå±‚(512->10)
    
    è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„å¤šå±‚æ„ŸçŸ¥æœº(MLP)ï¼Œé€‚åˆå…¥é—¨å­¦ä¹ 
    """
    def __init__(self):
        """åˆå§‹åŒ–ç½‘ç»œå±‚"""
        super().__init__()
        
        # å±•å¹³å±‚ï¼šå°†2Då›¾åƒè½¬æ¢ä¸º1Då‘é‡
        # (batch_size, 1, 28, 28) -> (batch_size, 784 = 28*28)
        self.flatten = nn.Flatten()
        
        # å®šä¹‰çº¿æ€§å±‚å †å ï¼ˆå…¨è¿æ¥ç½‘ç»œï¼‰
        self.linear_relu_stack = nn.Sequential(
            # ç¬¬ä¸€ä¸ªéšè—å±‚ï¼š784ä¸ªè¾“å…¥ -> 512ä¸ªç¥ç»å…ƒ
            nn.Linear(28*28, 512),   # 28*28=784 (å±•å¹³åçš„å›¾åƒåƒç´ )
            nn.ReLU(),               # ReLUæ¿€æ´»å‡½æ•°ï¼šf(x) = max(0,x)
            
            # ç¬¬äºŒä¸ªéšè—å±‚ï¼š512 -> 512
            nn.Linear(512, 512),
            nn.ReLU(),
            
            # è¾“å‡ºå±‚ï¼š512 -> 10 (10ä¸ªç±»åˆ«)
            nn.Linear(512, 10)       # ä¸åŠ æ¿€æ´»å‡½æ•°ï¼Œè¾“å‡ºåŸå§‹logits
        )

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­å‡½æ•°
        
        Args:
            x: è¾“å…¥å›¾åƒå¼ é‡ (batch_size, 1, 28, 28)
            
        Returns:
            logits: åˆ†ç±»å¾—åˆ† (batch_size, 10)
        """
        # æ­¥éª¤1ï¼šå±•å¹³å›¾åƒ
        x = self.flatten(x)
        # æ­¥éª¤2ï¼šé€šè¿‡å…¨è¿æ¥å±‚
        logits = self.linear_relu_stack(x)
        return logits

# åˆ›å»ºæ¨¡å‹å®ä¾‹å¹¶ç§»åŠ¨åˆ°é€‰å®šè®¾å¤‡
model = NeuralNetwork().to(device)

print(f"\næ¨¡å‹æ¶æ„ï¼š")
print(model)

# ç»Ÿè®¡æ¨¡å‹å‚æ•°
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"\næ¨¡å‹ç»Ÿè®¡ï¼š")
print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
print(f"æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")

######################################################################
# äº†è§£æ›´å¤šå…³äº `åœ¨PyTorchä¸­æ„å»ºç¥ç»ç½‘ç»œ <buildmodel_tutorial.html>`_ çš„å†…å®¹ã€‚
#


######################################################################
# --------------
#


#####################################################################
# ä¼˜åŒ–æ¨¡å‹å‚æ•°
# ----------------------------------------
print("\n" + "="*60)
print("æ­¥éª¤3ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨")
print("="*60)

# è¦è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª `æŸå¤±å‡½æ•° <https://pytorch.org/docs/stable/nn.html#loss-functions>`_
# å’Œä¸€ä¸ª `ä¼˜åŒ–å™¨ <https://pytorch.org/docs/stable/optim.html>`_ã€‚
#
# æŸå¤±å‡½æ•°ï¼šè¡¡é‡æ¨¡å‹é¢„æµ‹ä¸çœŸå®æ ‡ç­¾çš„å·®è·
# ä¼˜åŒ–å™¨ï¼šæ ¹æ®æŸå¤±å‡½æ•°çš„æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°

# é€‰æ‹©æŸå¤±å‡½æ•°
# CrossEntropyLossï¼šå¤šåˆ†ç±»ä»»åŠ¡çš„æ ‡å‡†é€‰æ‹©
# å®ƒç»“åˆäº†LogSoftmaxå’ŒNLLLossï¼Œæ•°å€¼ä¸Šæ›´ç¨³å®š
loss_fn = nn.CrossEntropyLoss()
print("æŸå¤±å‡½æ•°: CrossEntropyLoss")
print("- é€‚ç”¨äºå¤šåˆ†ç±»ä»»åŠ¡")
print("- è‡ªåŠ¨åº”ç”¨softmaxè½¬æ¢")
print("- æ•°å€¼ç¨³å®šæ€§å¥½")

# é€‰æ‹©ä¼˜åŒ–å™¨
# SGDï¼šéšæœºæ¢¯åº¦ä¸‹é™ï¼Œç»å…¸ä¸”å¯é çš„ä¼˜åŒ–ç®—æ³•
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
print(f"\nä¼˜åŒ–å™¨: SGD")
print(f"å­¦ä¹ ç‡: {1e-3}")
print("SGDç‰¹ç‚¹ï¼š")
print("- ç®€å•å¯é ")
print("- æ”¶æ•›ç¨³å®š")
print("- é€‚åˆå…¥é—¨å­¦ä¹ ")


#######################################################################
# è®­ç»ƒå‡½æ•°
# åœ¨å•ä¸ªè®­ç»ƒå¾ªç¯ä¸­ï¼Œæ¨¡å‹å¯¹è®­ç»ƒæ•°æ®é›†è¿›è¡Œé¢„æµ‹ï¼ˆåˆ†æ‰¹è¾“å…¥ï¼‰ï¼Œ
# å¹¶åå‘ä¼ æ’­é¢„æµ‹è¯¯å·®æ¥è°ƒæ•´æ¨¡å‹çš„å‚æ•°ã€‚
#
# è®­ç»ƒå¾ªç¯çš„æ ‡å‡†æ­¥éª¤ï¼š
# 1. å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹ç»“æœ
# 2. è®¡ç®—æŸå¤±ï¼šæ¯”è¾ƒé¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
# 3. åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
# 4. å‚æ•°æ›´æ–°ï¼šæ ¹æ®æ¢¯åº¦æ›´æ–°æƒé‡
# 5. æ¸…é›¶æ¢¯åº¦ï¼šä¸ºä¸‹æ¬¡è¿­ä»£å‡†å¤‡

def train(dataloader, model, loss_fn, optimizer):
    """
    è®­ç»ƒå‡½æ•°ï¼šæ‰§è¡Œä¸€ä¸ªepochçš„è®­ç»ƒ
    
    Args:
        dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        model: è¦è®­ç»ƒçš„æ¨¡å‹
        loss_fn: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
    """
    # è·å–æ•°æ®é›†å¤§å°ç”¨äºè¿›åº¦æ˜¾ç¤º
    size = len(dataloader.dataset)
    
    # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    # è¿™ä¼šå¯ç”¨Dropoutã€BatchNormç­‰è®­ç»ƒæ—¶çš„ç‰¹æ®Šè¡Œä¸º
    model.train()
    
    # éå†æ¯ä¸ªæ‰¹æ¬¡
    for batch, (X, y) in enumerate(dataloader):
        # å°†æ•°æ®ç§»åŠ¨åˆ°è®¡ç®—è®¾å¤‡
        X, y = X.to(device), y.to(device)

        # å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹
        pred = model(X)
        
        # è®¡ç®—æŸå¤±
        loss = loss_fn(pred, y)

        # åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
        loss.backward()
        
        # æ›´æ–°å‚æ•°
        optimizer.step()
        
        # æ¸…é›¶æ¢¯åº¦ï¼ˆPyTorchä¸­æ¢¯åº¦ä¼šç´¯ç§¯ï¼‰
        optimizer.zero_grad()

        # æ¯100ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡è®­ç»ƒçŠ¶æ€
        if batch % 100 == 0:
            loss_value = loss.item()  # è·å–æŸå¤±çš„æ•°å€¼
            current = (batch + 1) * len(X)  # å½“å‰å¤„ç†çš„æ ·æœ¬æ•°
            print(f"æŸå¤±: {loss_value:>7f}  [{current:>5d}/{size:>5d}]")

##############################################################################
# æµ‹è¯•å‡½æ•°
# æˆ‘ä»¬è¿˜è¦æ£€æŸ¥æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œä»¥ç¡®ä¿å®ƒæ­£åœ¨å­¦ä¹ ã€‚

def test(dataloader, model, loss_fn):
    """
    æµ‹è¯•å‡½æ•°ï¼šè¯„ä¼°æ¨¡å‹æ€§èƒ½
    
    Args:
        dataloader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        model: è¦è¯„ä¼°çš„æ¨¡å‹  
        loss_fn: æŸå¤±å‡½æ•°
    """
    size = len(dataloader.dataset)  # æµ‹è¯•é›†å¤§å°
    num_batches = len(dataloader)   # æ‰¹æ¬¡æ•°é‡
    
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    # è¿™ä¼šç¦ç”¨Dropoutã€BatchNormç­‰è®­ç»ƒæ—¶çš„éšæœºæ€§
    model.eval()
    
    test_loss, correct = 0, 0
    
    # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆèŠ‚çœå†…å­˜å’Œè®¡ç®—ï¼‰
    with torch.no_grad():
        for X, y in dataloader:
            # å°†æ•°æ®ç§»åŠ¨åˆ°è®¡ç®—è®¾å¤‡
            X, y = X.to(device), y.to(device)
            
            # å‰å‘ä¼ æ’­
            pred = model(X)
            
            # ç´¯ç§¯æŸå¤±
            test_loss += loss_fn(pred, y).item()
            
            # è®¡ç®—å‡†ç¡®ç‡
            # pred.argmax(1)ï¼šè·å–æ¯è¡Œæœ€å¤§å€¼çš„ç´¢å¼•ï¼ˆé¢„æµ‹ç±»åˆ«ï¼‰
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()
    
    # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
    test_loss /= num_batches
    correct /= size
    print(f"æµ‹è¯•ç»“æœ: \n å‡†ç¡®ç‡: {(100*correct):>0.1f}%, å¹³å‡æŸå¤±: {test_loss:>8f} \n")

##############################################################################
# æ‰§è¡Œè®­ç»ƒå¾ªç¯
print("\n" + "="*60)
print("æ­¥éª¤4ï¼šå¼€å§‹è®­ç»ƒæ¨¡å‹")
print("="*60)

# è®­ç»ƒè¿‡ç¨‹åœ¨å‡ æ¬¡è¿­ä»£ï¼ˆ*epochs*ï¼‰ä¸­è¿›è¡Œã€‚åœ¨æ¯ä¸ªepochä¸­ï¼Œæ¨¡å‹å­¦ä¹ 
# å‚æ•°ä»¥åšå‡ºæ›´å¥½çš„é¢„æµ‹ã€‚æˆ‘ä»¬åœ¨æ¯ä¸ªepochæ‰“å°æ¨¡å‹çš„å‡†ç¡®ç‡å’ŒæŸå¤±ï¼›
# æˆ‘ä»¬å¸Œæœ›çœ‹åˆ°å‡†ç¡®ç‡éšç€æ¯ä¸ªepochçš„å¢åŠ è€Œå¢åŠ ï¼ŒæŸå¤±å‡å°‘ã€‚

epochs = 5  # è®­ç»ƒè½®æ•°
print(f"å¼€å§‹è®­ç»ƒï¼Œæ€»å…± {epochs} ä¸ªepoch")
print("Epochè¯´æ˜ï¼š")
print("- æ¯ä¸ªepochä»£è¡¨æ¨¡å‹çœ‹è¿‡æ‰€æœ‰è®­ç»ƒæ•°æ®ä¸€æ¬¡")  
print("- é€šå¸¸éœ€è¦å¤šä¸ªepochæ‰èƒ½æ”¶æ•›")
print("- å¯ä»¥é€šè¿‡éªŒè¯é›†è¡¨ç°æ¥å†³å®šä½•æ—¶åœæ­¢è®­ç»ƒ")

for t in range(epochs):
    print(f"Epoch {t+1}")
    print("-------------------------------")
    
    # æ‰§è¡Œè®­ç»ƒ
    train(train_dataloader, model, loss_fn, optimizer)
    
    # æ‰§è¡Œæµ‹è¯•è¯„ä¼°
    test(test_dataloader, model, loss_fn)

print("è®­ç»ƒå®Œæˆï¼")

######################################################################
# äº†è§£æ›´å¤šå…³äº `è®­ç»ƒä½ çš„æ¨¡å‹ <optimization_tutorial.html>`_ çš„å†…å®¹ã€‚
#

######################################################################
# --------------
#

######################################################################
# ä¿å­˜æ¨¡å‹
# -------------
print("\n" + "="*60)
print("æ­¥éª¤5ï¼šä¿å­˜å’ŒåŠ è½½æ¨¡å‹")
print("="*60)

# ä¿å­˜æ¨¡å‹çš„å¸¸è§æ–¹æ³•æ˜¯åºåˆ—åŒ–å†…éƒ¨çŠ¶æ€å­—å…¸ï¼ˆåŒ…å«æ¨¡å‹å‚æ•°ï¼‰ã€‚
# 
# æ¨¡å‹ä¿å­˜çš„é‡è¦æ€§ï¼š
# 1. é¿å…é‡å¤è®­ç»ƒ
# 2. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
# 3. å®éªŒç»“æœå¤ç°
# 4. è¿ç§»å­¦ä¹ çš„åŸºç¡€

print("ä¿å­˜æ¨¡å‹çŠ¶æ€å­—å…¸...")
torch.save(model.state_dict(), "model.pth")
print("å·²ä¿å­˜PyTorchæ¨¡å‹çŠ¶æ€åˆ° model.pth")

print("\næ¨¡å‹ä¿å­˜è¯´æ˜ï¼š")
print("- state_dict(): åŒ…å«æ‰€æœ‰å¯å­¦ä¹ çš„å‚æ•°")
print("- .pth æ˜¯PyTorchæ¨¡å‹æ–‡ä»¶çš„å¸¸ç”¨æ‰©å±•å")
print("- è¿™ç§æ–¹å¼åªä¿å­˜å‚æ•°ï¼Œä¸ä¿å­˜æ¨¡å‹ç»“æ„")

######################################################################
# åŠ è½½æ¨¡å‹
# ----------------------------
print("\næ­£åœ¨æ¼”ç¤ºæ¨¡å‹åŠ è½½...")

# åŠ è½½æ¨¡å‹çš„è¿‡ç¨‹åŒ…æ‹¬é‡æ–°åˆ›å»ºæ¨¡å‹ç»“æ„å¹¶å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°å…¶ä¸­ã€‚
# æ³¨æ„ï¼šåŠ è½½æ¨¡å‹éœ€è¦å…ˆå®šä¹‰ç›¸åŒçš„ç½‘ç»œæ¶æ„

# é‡æ–°åˆ›å»ºæ¨¡å‹å®ä¾‹
print("1. é‡æ–°åˆ›å»ºæ¨¡å‹æ¶æ„...")
model = NeuralNetwork().to(device)

# åŠ è½½ä¿å­˜çš„å‚æ•°
print("2. åŠ è½½ä¿å­˜çš„å‚æ•°...")
model.load_state_dict(torch.load("model.pth", weights_only=True))

print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
print("æ³¨æ„ï¼šweights_only=True ç¡®ä¿åªåŠ è½½æƒé‡ï¼Œæé«˜å®‰å…¨æ€§")

#############################################################
# ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
print("\n" + "="*60)
print("æ­¥éª¤6ï¼šä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹")
print("="*60)

# è¿™ä¸ªæ¨¡å‹ç°åœ¨å¯ä»¥ç”¨æ¥è¿›è¡Œé¢„æµ‹ã€‚
# å®šä¹‰FashionMNISTçš„ç±»åˆ«åç§°
classes = [
    "T-shirt/top",    # Tæ¤/ä¸Šè¡£
    "Trouser",        # è£¤å­  
    "Pullover",       # å¥—å¤´è¡«
    "Dress",          # è¿è¡£è£™
    "Coat",           # å¤–å¥—
    "Sandal",         # å‡‰é‹
    "Shirt",          # è¡¬è¡«
    "Sneaker",        # è¿åŠ¨é‹
    "Bag",            # åŒ…
    "Ankle boot",     # çŸ­é´
]

print(f"FashionMNISTæ•°æ®é›†åŒ…å«ä»¥ä¸‹ç±»åˆ«ï¼š")
for i, class_name in enumerate(classes):
    print(f"{i}: {class_name}")

# è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
model.eval()

# ä»æµ‹è¯•é›†ä¸­å–ä¸€ä¸ªæ ·æœ¬è¿›è¡Œé¢„æµ‹
x, y = test_data[0][0], test_data[0][1]  # ç¬¬ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
print(f"\né€‰æ‹©æµ‹è¯•æ ·æœ¬:")
print(f"å›¾åƒå½¢çŠ¶: {x.shape}")
print(f"çœŸå®æ ‡ç­¾: {y} ({classes[y]})")

# è¿›è¡Œé¢„æµ‹
with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
    # å°†è¾“å…¥ç§»åŠ¨åˆ°è®¾å¤‡å¹¶æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    x = x.to(device)
    
    # è·å–æ¨¡å‹é¢„æµ‹z
    # å°†è¾“å…¥å¼ é‡ x ä¼ é€’ç»™æ¨¡å‹ modelï¼Œå¾—åˆ°é¢„æµ‹ç»“æœ pred
    pred = model(x)
    
    # è·å–é¢„æµ‹çš„ç±»åˆ«å’Œç½®ä¿¡åº¦
    #pred[0] æ˜¯é¢„æµ‹çš„ç±»åˆ«å¾—åˆ†ï¼Œargmax(0) æ˜¯è·å–å¾—åˆ†æœ€é«˜çš„ç±»åˆ«ç´¢
    predicted_idx = pred[0].argmax(0).item() # è·å–é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•
    predicted_class = classes[predicted_idx]
    actual_class = classes[y]
    
    # è®¡ç®—é¢„æµ‹æ¦‚ç‡
    # softmax å‡½æ•°å°†é¢„æµ‹å¾—åˆ†è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡ä¹‹å’Œä¸º1
    # dim=0 è¡¨ç¤ºæŒ‰åˆ—è®¡ç®—æ¦‚ç‡ ï¼Œdim=1 è¡¨ç¤ºæŒ‰è¡Œè®¡ç®—æ¦‚ç‡ ï¼Œdim=None è¡¨ç¤ºæŒ‰æ‰€æœ‰ç»´åº¦è®¡ç®—æ¦‚ç‡
    # è¿™é‡Œä½¿ç”¨ dim=0 è¡¨ç¤ºæŒ‰åˆ—è®¡ç®—æ¦‚ç‡ï¼Œå³è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡
    # è¿”å›ä¸€ä¸ªåŒ…å«æ¯ä¸ªç±»åˆ«æ¦‚ç‡çš„å¼ é‡s
    probabilities = torch.nn.functional.softmax(pred[0], dim=0)
    confidence = probabilities[predicted_idx].item()
    
    print(f"\né¢„æµ‹ç»“æœ:")
    print(f'é¢„æµ‹ç±»åˆ«: "{predicted_class}" (ç½®ä¿¡åº¦: {confidence:.3f})')
    print(f'å®é™…ç±»åˆ«: "{actual_class}"')
    print(f'é¢„æµ‹{"æ­£ç¡®" if predicted_class == actual_class else "é”™è¯¯"}!')
    
    # æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡
    print(f"\næ‰€æœ‰ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡:")
    for i, (class_name, prob) in enumerate(zip(classes, probabilities)):
        marker = "ğŸ‘ˆ" if i == predicted_idx else "  "
        print(f"{i}: {class_name:12} {prob:.3f} {marker}")

######################################################################
# äº†è§£æ›´å¤šå…³äº `ä¿å­˜å’ŒåŠ è½½ä½ çš„æ¨¡å‹ <saveloadrun_tutorial.html>`_ çš„å†…å®¹ã€‚
#

print("\n" + "="*60)
print("æ•™ç¨‹æ€»ç»“")
print("="*60)
print("æ­å–œï¼ä½ å·²ç»å®Œæˆäº†PyTorchå¿«é€Ÿå…¥é—¨æ•™ç¨‹")
print("\nå­¦åˆ°çš„å…³é”®æ¦‚å¿µï¼š")
print("1. ğŸ“Š æ•°æ®åŠ è½½ï¼šDatasetå’ŒDataLoaderçš„ä½¿ç”¨")
print("2. ğŸ§  æ¨¡å‹å®šä¹‰ï¼šç»§æ‰¿nn.Moduleåˆ›å»ºç¥ç»ç½‘ç»œ")
print("3. ğŸ¯ è®­ç»ƒè¿‡ç¨‹ï¼šæŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ã€è®­ç»ƒå¾ªç¯")
print("4. ğŸ“ˆ æ¨¡å‹è¯„ä¼°ï¼šå‡†ç¡®ç‡è®¡ç®—å’Œæ€§èƒ½ç›‘æ§")
print("5. ğŸ’¾ æ¨¡å‹æŒä¹…åŒ–ï¼šä¿å­˜å’ŒåŠ è½½æ¨¡å‹çŠ¶æ€")
print("6. ğŸ”® å®é™…åº”ç”¨ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹")

print("\nä¸‹ä¸€æ­¥å»ºè®®ï¼š")
print("- å°è¯•ä¸åŒçš„ç½‘ç»œæ¶æ„ï¼ˆCNNã€RNNç­‰ï¼‰")
print("- å®éªŒä¸åŒçš„ä¼˜åŒ–å™¨ï¼ˆAdamã€AdamWç­‰ï¼‰")
print("- å­¦ä¹ æ•°æ®å¢å¼ºæŠ€æœ¯")
print("- æ¢ç´¢è¿ç§»å­¦ä¹ ")
print("- ç ”ç©¶æ›´å¤æ‚çš„æ•°æ®é›†")

print("\nå¿«ä¹çš„PyTorchå­¦ä¹ ä¹‹æ—…ï¼ğŸš€")
