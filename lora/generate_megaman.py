#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Mega Man LoRA åœ–åƒç”Ÿæˆè…³æœ¬
ä½¿ç”¨è¨“ç·´å¥½çš„ LoRA æ¨¡å‹ç”Ÿæˆ Mega Man é¢¨æ ¼çš„åœ–åƒ
"""

import torch
import argparse
from pathlib import Path
from PIL import Image
import json
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
from peft import PeftModel
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_lora_model(base_model_path, lora_path, device="cuda"):
    """è¼‰å…¥ LoRA æ¨¡å‹"""
    logger.info(f"è¼‰å…¥åŸºç¤æ¨¡å‹: {base_model_path}")
    
    # è¼‰å…¥åŸºç¤ Stable Diffusion ç®¡é“
    pipe = StableDiffusionPipeline.from_pretrained(
        base_model_path,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,
        requires_safety_checker=False,
    )
    
    # ä½¿ç”¨æ›´å¿«çš„èª¿åº¦å™¨
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
    
    # è¼‰å…¥ LoRA æ¬Šé‡
    if Path(lora_path).exists():
        logger.info(f"è¼‰å…¥ LoRA æ¬Šé‡: {lora_path}")
        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path)
        
        # è¼‰å…¥è¨“ç·´é…ç½®
        config_path = Path(lora_path).parent / "training_config.json"
        if config_path.exists():
            with open(config_path, 'r') as f:
                config = json.load(f)
                logger.info(f"LoRA é…ç½®: Rank={config.get('lora_rank', 'Unknown')}, "
                           f"Alpha={config.get('lora_alpha', 'Unknown')}")
    else:
        logger.warning(f"LoRA è·¯å¾‘ä¸å­˜åœ¨: {lora_path}")
    
    # ç§»å‹•åˆ°è¨­å‚™
    pipe = pipe.to(device)
    
    # å•Ÿç”¨è¨˜æ†¶é«”æ•ˆç‡å„ªåŒ–
    if device == "cuda":
        pipe.enable_model_cpu_offload()
        pipe.enable_xformers_memory_efficient_attention()
        pipe.enable_vae_slicing()
    
    return pipe

def generate_images(pipe, prompts, output_dir, args):
    """ç”Ÿæˆåœ–åƒ"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"é–‹å§‹ç”Ÿæˆ {len(prompts)} å€‹æç¤ºè©çš„åœ–åƒ...")
    
    all_images = []
    
    for i, prompt in enumerate(prompts):
        logger.info(f"ç”Ÿæˆæç¤ºè© {i+1}/{len(prompts)}: {prompt}")
        
        # ç”Ÿæˆåœ–åƒ
        with torch.no_grad():
            images = pipe(
                prompt=prompt,
                negative_prompt=args.negative_prompt,
                num_images_per_prompt=args.num_images_per_prompt,
                num_inference_steps=args.num_inference_steps,
                guidance_scale=args.guidance_scale,
                height=args.height,
                width=args.width,
                generator=torch.Generator(device=pipe.device).manual_seed(args.seed + i) if args.seed else None,
            ).images
        
        # ä¿å­˜åœ–åƒ
        for j, image in enumerate(images):
            filename = f"megaman_{i:03d}_{j:02d}.png"
            image_path = output_path / filename
            image.save(image_path)
            all_images.append((prompt, image_path))
            logger.info(f"ä¿å­˜åœ–åƒ: {image_path}")
    
    # å‰µå»ºåœ–åƒç´¢å¼•
    create_image_index(all_images, output_path)
    
    logger.info(f"æ‰€æœ‰åœ–åƒå·²ä¿å­˜åˆ°: {output_path}")

def create_image_index(images, output_dir):
    """å‰µå»ºåœ–åƒç´¢å¼• HTML æ–‡ä»¶"""
    html_content = """
<!DOCTYPE html>
<html>
<head>
    <title>Mega Man LoRA ç”Ÿæˆåœ–åƒ</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .gallery { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
        .image-item { border: 1px solid #ddd; padding: 10px; border-radius: 8px; }
        .image-item img { max-width: 100%; height: auto; border-radius: 4px; }
        .prompt { margin-top: 10px; font-size: 14px; color: #666; }
        h1 { color: #333; text-align: center; }
    </style>
</head>
<body>
    <h1>ğŸ¤– Mega Man LoRA ç”Ÿæˆåœ–åƒ ğŸ®</h1>
    <div class="gallery">
"""
    
    for prompt, image_path in images:
        filename = image_path.name
        html_content += f"""
        <div class="image-item">
            <img src="{filename}" alt="Generated Mega Man">
            <div class="prompt"><strong>æç¤ºè©:</strong> {prompt}</div>
        </div>
"""
    
    html_content += """
    </div>
</body>
</html>
"""
    
    with open(output_dir / "index.html", "w", encoding="utf-8") as f:
        f.write(html_content)

def get_default_prompts():
    """ç²å–é»˜èªçš„ Mega Man æç¤ºè©"""
    return [
        "mega man, blue robot, helmet, game character, high quality, detailed",
        "mega man X, futuristic armor, blue and white, sci-fi style, 4k",
        "mega man zero, red and white robot, sword, action pose, dynamic",
        "classic mega man, 8-bit style, retro gaming, pixelated",
        "mega man battle network, digital world, cyber style, neon lights",
        "mega man boss robot, unique design, colorful armor, threatening pose",
        "mega man charging mega buster, energy beam, blue glow, powerful",
        "mega man running, side view, classic platformer style, detailed",
        "mega man helmet close-up, detailed face, blue armor, high resolution",
        "mega man vs robot master, epic battle, explosions, dynamic scene"
    ]

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ Mega Man LoRA ç”Ÿæˆåœ–åƒ")
    
    # æ¨¡å‹åƒæ•¸
    parser.add_argument("--base_model", type=str, default="runwayml/stable-diffusion-v1-5",
                       help="åŸºç¤ Stable Diffusion æ¨¡å‹")
    parser.add_argument("--lora_path", type=str, default="./megaman_lora_output/lora_weights",
                       help="LoRA æ¬Šé‡è·¯å¾‘")
    parser.add_argument("--output_dir", type=str, default="./generated_megaman",
                       help="ç”Ÿæˆåœ–åƒè¼¸å‡ºç›®éŒ„")
    
    # ç”Ÿæˆåƒæ•¸
    parser.add_argument("--prompts", type=str, nargs="*", default=None,
                       help="è‡ªå®šç¾©æç¤ºè©åˆ—è¡¨")
    parser.add_argument("--prompts_file", type=str, default=None,
                       help="åŒ…å«æç¤ºè©çš„æ–‡æœ¬æ–‡ä»¶ (æ¯è¡Œä¸€å€‹)")
    parser.add_argument("--negative_prompt", type=str, 
                       default="blurry, low quality, distorted, deformed, ugly, bad anatomy",
                       help="è² é¢æç¤ºè©")
    parser.add_argument("--num_images_per_prompt", type=int, default=1,
                       help="æ¯å€‹æç¤ºè©ç”Ÿæˆçš„åœ–åƒæ•¸é‡")
    parser.add_argument("--num_inference_steps", type=int, default=25,
                       help="æ¨ç†æ­¥æ•¸")
    parser.add_argument("--guidance_scale", type=float, default=7.5,
                       help="å¼•å°æ¯”ä¾‹")
    parser.add_argument("--height", type=int, default=512,
                       help="åœ–åƒé«˜åº¦")
    parser.add_argument("--width", type=int, default=512,
                       help="åœ–åƒå¯¬åº¦")
    parser.add_argument("--seed", type=int, default=42,
                       help="éš¨æ©Ÿç¨®å­")
    parser.add_argument("--device", type=str, default="cuda",
                       choices=["cuda", "cpu"], help="è¨ˆç®—è¨­å‚™")
    
    args = parser.parse_args()
    
    # æª¢æŸ¥è¨­å‚™
    if args.device == "cuda" and not torch.cuda.is_available():
        logger.warning("CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
        args.device = "cpu"
    
    # æº–å‚™æç¤ºè©
    if args.prompts_file:
        logger.info(f"å¾æ–‡ä»¶è¼‰å…¥æç¤ºè©: {args.prompts_file}")
        with open(args.prompts_file, 'r', encoding='utf-8') as f:
            prompts = [line.strip() for line in f if line.strip()]
    elif args.prompts:
        prompts = args.prompts
    else:
        logger.info("ä½¿ç”¨é»˜èªæç¤ºè©")
        prompts = get_default_prompts()
    
    logger.info(f"å°‡ç”Ÿæˆ {len(prompts)} å€‹æç¤ºè©çš„åœ–åƒ")
    
    # è¼‰å…¥æ¨¡å‹
    pipe = load_lora_model(args.base_model, args.lora_path, args.device)
    
    # ç”Ÿæˆåœ–åƒ
    generate_images(pipe, prompts, args.output_dir, args)
    
    logger.info("åœ–åƒç”Ÿæˆå®Œæˆï¼")
    logger.info(f"æŸ¥çœ‹çµæœ: æ‰“é–‹ {args.output_dir}/index.html")

if __name__ == "__main__":
    main()

"""
ä½¿ç”¨ç¤ºä¾‹:

1. ä½¿ç”¨é»˜èªæç¤ºè©ç”Ÿæˆ:
python generate_megaman.py --lora_path ./megaman_lora_output/lora_weights

2. ä½¿ç”¨è‡ªå®šç¾©æç¤ºè©:
python generate_megaman.py \
    --lora_path ./megaman_lora_output/lora_weights \
    --prompts "mega man X, detailed armor, action pose" "classic mega man, 8-bit style"

3. å¾æ–‡ä»¶è¼‰å…¥æç¤ºè©:
python generate_megaman.py \
    --lora_path ./megaman_lora_output/lora_weights \
    --prompts_file prompts.txt

4. é«˜è³ªé‡ç”Ÿæˆ:
python generate_megaman.py \
    --lora_path ./megaman_lora_output/lora_weights \
    --height 768 \
    --width 768 \
    --num_inference_steps 50 \
    --guidance_scale 10.0 \
    --num_images_per_prompt 4
""" 