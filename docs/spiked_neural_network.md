ä½ é‡åˆ°çš„éŒ¯èª¤æ˜¯ï¼š

```
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
```

é€™è¡¨ç¤º `loss` æ˜¯å€‹ä¸åƒèˆ‡æ¢¯åº¦é‹ç®—çš„å¼µé‡ï¼Œå°è‡´ç„¡æ³• `.backward()`ã€‚é€šå¸¸é€™æ˜¯å› ç‚ºæ¨¡å‹è¼¸å‡ºç¶“é `.detach()`ã€`torch.no_grad()`ï¼Œæˆ– **æŸå€‹è‡ªè¨‚å‡½æ•¸ä¸­ç¼ºå°‘éœ€è¦æ¢¯åº¦çš„é‹ç®—éç¨‹**ã€‚

---

### âœ… è§£æ±ºæ–¹æ³•ï¼š

è«‹æª¢æŸ¥ä½ çš„ `spike_loss` å‡½æ•¸ï¼š

```python
def spike_loss(predictions, targets):
    spike_counts = predictions.sum(dim=1)
    targets = targets.long()
    return torch.nn.functional.cross_entropy(spike_counts, targets)
```

é€™æ®µçœ‹èµ·ä¾†æ²’å•é¡Œã€‚å•é¡Œå¯èƒ½ä¾†è‡ªä½ çš„ `IntegrateAndFireNeuron` ç¥ç¶“å…ƒçš„ `forward()` å‡½æ•¸è£¡é€™è¡Œï¼š

```python
output = (self.membrane_potential >= self.threshold).float()
```

é€™æ˜¯ä¸€å€‹ **éå¯å¾®åˆ†é‹ç®—**ï¼ˆå› ç‚ºæ¯”è¼ƒé‹ç®— + `.float()`ï¼‰ï¼Œ**é€™æ¨£åšä¸æœƒç”¢ç”Ÿ `grad_fn`ï¼Œå› æ­¤å¾Œé¢æ‰€æœ‰æ¢¯åº¦è¨ˆç®—éƒ½æœƒå¤±æ•ˆ**ã€‚

---

### ğŸ§  ä¿®æ­£æ–¹æ¡ˆï¼šä½¿ç”¨ surrogate gradient

å°–å³°ç¥ç¶“ç¶²è·¯é€šå¸¸æœƒåœ¨è¨“ç·´æ™‚ä½¿ç”¨ã€Œè¿‘ä¼¼å¯å°çš„ surrogate functionã€ä»£æ›¿ hard thresholdingï¼Œä»¥ä¸‹æ˜¯ä¸€å€‹ç°¡åŒ–ç‰ˆæœ¬ï¼š

#### ğŸ§¬ æ›¿æ› `IntegrateAndFireNeuron.forward()` è£¡çš„é€™æ®µï¼š

```python
output = (self.membrane_potential >= self.threshold).float()
```

#### æ”¹æˆï¼š

```python
# surrogate spike activation
# sigmoid å¯å°ï¼Œè¿‘ä¼¼ spike æ¢ä»¶
surrogate_grad = torch.sigmoid(10 * (self.membrane_potential - self.threshold))
output = surrogate_grad
```

ä½ ä¹Ÿå¯ä»¥è‡ªå·±å®šç¾©ä¸€å€‹å¯å¾®è¿‘ä¼¼å‡½æ•¸ï¼Œä¾‹å¦‚ï¼š

```python
class SurrogateSpike(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input, threshold):
        ctx.save_for_backward(input)
        return (input >= threshold).float()

    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        grad_input = grad_output.clone()
        # å¹³æ»‘è¿‘ä¼¼çš„æ¢¯åº¦å‡½æ•¸ï¼ˆå¦‚ sigmoid å°æ•¸ï¼‰
        return grad_input * torch.sigmoid(10 * (input - 1)) * (1 - torch.sigmoid(10 * (input - 1))) * 10, None
```

ç„¶å¾Œåœ¨ä½ çš„ neuron è£¡ï¼š

```python
output = SurrogateSpike.apply(self.membrane_potential, self.threshold)
```

---

### âœ… å¦éœ€æ³¨æ„çš„é»

1. `membrane_potential` éœ€åœ¨æ¯å€‹ batch é–‹é ­é‡è¨­ï¼ˆå¯åœ¨ `SimpleSpikingNeuralNetwork.forward()` å‰åŠ  reset å‡½æ•¸ï¼‰
2. è‹¥ `output` æ°¸é éƒ½æ˜¯ 0 æˆ– 1ï¼Œæ²’æœ‰é€£çºŒå€¼ï¼Œå‰‡ä¸æœƒåƒèˆ‡åå‘å‚³æ’­
3. surrogate gradient åªåœ¨è¨“ç·´éšæ®µä½¿ç”¨ï¼Œæ¸¬è©¦éšæ®µä»å¯ä½¿ç”¨ `(x >= threshold).float()`

---

### âœ… å»ºè­°åšæ³•ç¸½çµ

* ğŸ”„ ä½¿ç”¨å¯å¾®åˆ† surrogate å‡½æ•¸æ›¿ä»£ hard threshold
* ğŸ” åŠ å…¥ `reset_state()` ä»¥æ¸…é™¤è†œé›»ä½
* âœ… ä¿è­‰æ¯ä¸€æ­¥éƒ½æœ‰ `requires_grad=True` çš„æ“ä½œéˆ

---

å¦‚æœä½ æƒ³æˆ‘å¹«ä½ ä¿®æ”¹æ•´ä»½ç¨‹å¼ç¢¼å¥—ç”¨ surrogate gradientï¼ˆä¾‹å¦‚ç”¨ sigmoid æˆ– soft spike å‡½æ•¸ï¼‰ï¼Œæˆ‘å¯ä»¥é¦¬ä¸Šå¹«ä½ æ”¹å¯«ã€‚è¦å—ï¼Ÿ
